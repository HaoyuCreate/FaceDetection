{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35565a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a40046a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three usful funiton for head-pose estimation\n",
    "def Ref3DModel():\n",
    "    modelPoints = [[0.0, 0.0, 0.0],\n",
    "                   [0.0, -330.0, -65.0],\n",
    "                   [-225.0, 170.0, -135.0],\n",
    "                   [225.0, 170.0, -135.0],\n",
    "                   [-150.0, -150.0, -125.0],\n",
    "                   [150.0, -150.0, -125.0]]\n",
    "    return np.array(modelPoints, dtype=np.float64)\n",
    "\n",
    "\n",
    "def Ref2dImagePoints(landmarks):\n",
    "    imagePoints = [[landmarks.part(30).x, landmarks.part(30).y],  # Nose tip \n",
    "                   [landmarks.part(8).x,  landmarks.part(8).y ],  # Chin \n",
    "                   [landmarks.part(36).x, landmarks.part(36).y],  # Left eye left corner \n",
    "                   [landmarks.part(45).x, landmarks.part(45).y],  # Right eye right corne \n",
    "                   [landmarks.part(48).x, landmarks.part(48).y],  # Left Mouth corner        \n",
    "                   [landmarks.part(54).x, landmarks.part(54).y]]  # Right mouth corner       \n",
    "    return np.array(imagePoints, dtype=np.float64)\n",
    "\n",
    "\n",
    "def CameraMatrix(fl, center):\n",
    "    cameraMatrix = [[fl, 1, center[0]],\n",
    "                    [0, fl, center[1]],\n",
    "                    [0, 0, 1]]\n",
    "    return np.array(cameraMatrix, dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f300af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROIGenerator(img,area_rate=0.8):\n",
    "    if len(img.shape) == 1:\n",
    "        height, weight = img.shape\n",
    "    else:\n",
    "        height,weight,_ = img.shape\n",
    "    \n",
    "    ROI_rate = math.sqrt(area_rate)\n",
    "    roi_right = weight - int((weight-ROI_rate*weight)/2) \n",
    "    roi_bottom = height - int((height-ROI_rate*height)/2) \n",
    "    roi_left = int((weight-ROI_rate*weight)/2) \n",
    "    roi_top = int((height-ROI_rate*height)/2) \n",
    "    \n",
    "    ROI_bbx = [roi_bottom,roi_right,roi_top,roi_left]\n",
    "    return ROI_bbx\n",
    "\n",
    "def CalOcpyofROI(boxA, boxB): # boxA: face; boxB: ROI\n",
    "    # Per requst of the assignment, the ratio is similar to IoU\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 0\n",
    "    # compute the area of ROI\n",
    "    boxBBrea = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "\n",
    "    # compute the intersection over area of ROI\n",
    "    occupy = interArea / float(boxBBrea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return occupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e56ab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckinROI(ROI_bbx,face,area_rate=0.8):\n",
    "    face_bbx = [face.bottom(),face.right(),face.top(),face.left()]\n",
    "    return (CalOcpyofROI(face_bbx,ROI_bbx) >= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2cde254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalDistance(img,face):\n",
    "    # calculate the distance between the detected face and image center \n",
    "    if len(img.shape) == 1:\n",
    "        height, weight = img.shape\n",
    "    else:\n",
    "        height,weight,_ = img.shape\n",
    "    \n",
    "    img_center =  np.array([int(height/2), int(weight/2)])\n",
    "    face_center = np.array([int((face.left()+face.right())/2),int((face.top()+face.bottom())/2)])\n",
    "    return math.sqrt(sum((face_center - img_center)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc78c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeadPoseDetector(img,landmarks):\n",
    "    height,width,_ = img.shape\n",
    "    focal_length = 1 * width\n",
    "    \n",
    "    camera_matrix = CameraMatrix(focal_length,(height / 2, width / 2))\n",
    "    face_3d_model = Ref3DModel()\n",
    "    ref_img_pts = Ref2dImagePoints(landmarks)\n",
    "    mdists = np.zeros((4, 1), dtype=np.float64) # Assuming no lens\n",
    "    \n",
    "    # calculate rotation and translation vector using solvePnP\n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(face_3d_model,\n",
    "                                        ref_img_pts,\n",
    "                                        camera_matrix,\n",
    "                                        mdists)\n",
    "    \n",
    "    # calculate nose start and nose end \n",
    "    nose_end_point, _ = cv2.projectPoints(np.array([(0.0, 0.0, 500.0)]),\n",
    "                                        rotation_vector,\n",
    "                                        translation_vector,\n",
    "                                        camera_matrix,\n",
    "                                        mdists)\n",
    "     \n",
    "    p1 = ( int(ref_img_pts[0][0]), int(ref_img_pts[0][1])) # start\n",
    "    p2 = ( int(nose_end_point[0][0][0]), int(nose_end_point[0][0][1])) # end\n",
    "    \n",
    "    return p1,p2 #theta and phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca2dd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector =dlib.get_frontal_face_detector()\n",
    "predictor=dlib.shape_predictor(\"landmarks/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "Colors = [(0,255,0),(0,0,255)] #0:green = focused; 1:red = unfocused\n",
    "\n",
    "while cap.isOpened() :\n",
    "    color_flag = []\n",
    "    distance_list = []\n",
    "    \n",
    "    _,frame =cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=detector(gray)\n",
    "    \n",
    "    # generate ROI, ROI_ares = area_rate * image_area\n",
    "    roi = ROIGenerator(frame,area_rate=0.8)\n",
    "    roi_bottom,roi_right,roi_top,roi_left = roi\n",
    "    cv2.rectangle(frame,(roi_left,roi_top),(roi_right,roi_bottom),(0,255,255),1)\n",
    "    \n",
    "    for face in faces:\n",
    "        color_flag.append(Colors[1])\n",
    "        distance_list.append(CalDistance(frame,face))\n",
    "    \n",
    "    if distance_list:\n",
    "        color_flag[distance_list.index(min(distance_list))] = Colors[0] # find the first nearest face\n",
    "        \n",
    "    \n",
    "    for face,color in zip(faces,color_flag) :\n",
    "        # Check if the face in ROI \n",
    "        if CheckinROI(roi,face): break\n",
    "        \n",
    "        # Detect the landmarks\n",
    "        landmarks = predictor(gray,face)\n",
    "        \n",
    "        # Estimate head pose\n",
    "        pose_start,pose_end = HeadPoseDetector(frame,landmarks)\n",
    "            \n",
    "        # drawing the face detection\n",
    "        cv2.rectangle(frame,(face.left(),face.top()),(face.right(),face.bottom()),color,3)\n",
    "        \n",
    "        # drawing the landmarks \n",
    "        for n in range (68) :\n",
    "            x=landmarks.part(n).x\n",
    "            y=landmarks.part(n).y\n",
    "            cv2.circle(frame,(x,y),2,color,-1)\n",
    "              \n",
    "        # drawing the head pose \n",
    "        cv2.line(frame, pose_start, pose_end, (255,0,0), 2)\n",
    "        cv2.imshow('Face Detection',frame)\n",
    "        \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a18a315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
